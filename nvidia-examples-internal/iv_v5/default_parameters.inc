#!/bin/bash

WORKSPACE=${WORKSPACE:-"/workspace"}
MODEL_PATH=${MODEL_PATH:-"$WORKSPACE/models/IntelligentVoice_en-US_8kHz_40000_general_V5_ASRv5/"}

MODEL_NAME=${MODEL_NAME:-"iv_en_us"}
DATASET=${DATASET:-"$WORKSPACE/datasets/IntelligentVoice_V5/test_enron"}

GPU=${GPU:-0}
GPU_THREADS=${GPU_THREADS:-2}
CPU_THREADS=${CPU_THREADS:-80}
COPY_THREADS=${COPY_THREADS:-2}
FRAME_SUBSAMPLING_FACTOR=${FRAME_SUBSAMPLING_FACTOR:-3}
FRAMES_PER_CHUNK=${FRAMES_PER_CHUNK:-264}

BEAM=${BEAM:-15}
LATTICE_BEAM=${LATTICE_BEAM:-2.5}
MAX_ACTIVE=${MAX_ACTIVE:-7000}
MAIN_Q_CAPACITY=${MAIN_Q_CAPACITY:-30000}
AUX_Q_CAPACITY=${AUX_Q_CAPACITY:-400000}

MAX_BATCH_SIZE=${MAX_BATCH_SIZE:-100}
BATCH_DRAIN_SIZE=${BATCH_DRAIN_SIZE:-10}
GPU_FEATURES=${GPU_FEATURES:-"true"}
ITERATIONS=${ITERATIONS:-10}
USE_SEGMENTS_FILE=${USE_SEGMENTS_FILE:-"true"}

#query GPU memory
#gpu_memory=`nvidia-smi -q -i $GPU | grep -A1 "FB Memory" | grep Total | tr -s " " | cut -d " " -f 4`
#if [ $gpu_memory -ge 32000 ]; then
#  MAX_BATCH_SIZE=${MAX_BATCH_SIZE:-100}
#  BATCH_DRAIN_SIZE=${BATCH_DRAIN_SIZE:-10}
#elif [ $gpu_memory -ge 16000 ]; then
#  MAX_BATCH_SIZE=${MAX_BATCH_SIZE:-100}
#  BATCH_DRAIN_SIZE=${BATCH_DRAIN_SIZE:-10}
#elif [ $gpu_memory -ge 8000 ]; then
#  MAX_BATCH_SIZE=${MAX_BATCH_SIZE:-50}
#  BATCH_DRAIN_SIZE=${BATCH_DRAIN_SIZE:-5}
#elif [ $gpu_memory -ge 4000 ]; then
#  MAX_BATCH_SIZE=${MAX_BATCH_SIZE:-25}
#  BATCH_DRAIN_SIZE=${BATCH_DRAIN_SIZE:-2}
#else
#  echo "ERROR not enough GPU memory to run benchmark."
#  exit 1;
#fi

